{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **CS570 - Homework 2**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "In this assignment we will implement the **GraphSAGE** ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)) layer and **GAT** ([Veličković et al. (2018)](https://arxiv.org/abs/1710.10903)) layer. Then we will run our models on the CORA dataset, which is a standard node classification dataset on a citation network benchmark.\n",
        "\n",
        "**Note**: Make sure to **sequentially run all the cells in each section** so that the intermediate variables / packages will carry over to the next cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSaetj53YnT6"
      },
      "source": [
        "# Device\n",
        "We recommend using a GPU for this assignment.\n",
        "\n",
        "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gOQITlCNQi"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_m9l6OYCQZP",
        "outputId": "4e2ea5a6-b238-4db4-e36e-aa5d4a72a7ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 3.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 17.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.13\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 20.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.63.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=c8a1e7f2f8d82abfc2d9a7906f56e251cb051336ada196edeea7e0f6a8faedc0\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n"
          ]
        }
      ],
      "source": [
        "# Install torch geometric\n",
        "import os\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PRfgbfTjCRD_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7f3969e0-9cf9-4145-cb54-03f097f35192"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch_geometric\n",
        "torch_geometric.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoXlf4MtYrbz"
      },
      "source": [
        "# 1) GNN Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQy2RBfgYut4"
      },
      "source": [
        "## Implementing Layer Modules\n",
        "For this assignment, we provide a build upon a general Graph Neural Network Stack, into which we will be able to plugin our own module implementations: GraphSAGE and GAT.\n",
        "\n",
        "We will then use our layer implemenations to complete node classification on the CORA dataset, a standard citation network benchmark. In this dataset, nodes correspond to documents and edges correspond to undirected citations. Each node or document in the graph is assigned a class label and features based on the documents binarized bag-of-words representation. Specifically, the Cora graph has 2708 nodes, 5429 edges, 7 prediction classes, and 1433 features per node. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4ne6Gw-CT5G"
      },
      "source": [
        "## GNN Stack Module\n",
        "\n",
        "Below is the implementation of a general GNN stack, where we can plugin any GNN layer, such as **GraphSage**, **GAT**, etc. This module is provided for you. Your implementations of the **GraphSage** and **GAT** layers will function as components in the GNNStack Module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ys8vZAFPCWWe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch_scatter\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "from torch import Tensor\n",
        "from typing import Union, Tuple, Optional\n",
        "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
        "                                    OptTensor)\n",
        "\n",
        "from torch.nn import Parameter, Linear\n",
        "from torch_sparse import SparseTensor, set_diag\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
        "\n",
        "class GNNStack(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):\n",
        "        super(GNNStack, self).__init__()\n",
        "        conv_model = self.build_conv_model(args.model_type)\n",
        "        self.convs = nn.ModuleList()\n",
        "        \n",
        "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
        "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
        "        for l in range(args.num_layers-1):\n",
        "            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim))\n",
        "\n",
        "        # post-message-passing\n",
        "        self.post_mp = nn.Sequential(\n",
        "            nn.Linear(args.heads * hidden_dim, hidden_dim), nn.Dropout(args.dropout), \n",
        "            nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "        self.dropout = args.dropout\n",
        "        self.num_layers = args.num_layers\n",
        "\n",
        "        self.emb = emb\n",
        "\n",
        "    def build_conv_model(self, model_type):\n",
        "        if model_type == 'GraphSage':\n",
        "            return GraphSage #CHANGED TO TEST GAT\n",
        "        elif model_type == 'GAT':\n",
        "            # When applying GAT with num heads > 1, you need to modify the \n",
        "            # input and output dimension of the conv layers (self.convs),\n",
        "            # to ensure that the input dim of the next layer is num heads\n",
        "            # multiplied by the output dim of the previous layer.\n",
        "            # HINT: In case you want to play with multiheads, you need to change the for-loop that builds up self.convs to be\n",
        "            # self.convs.append(conv_model(hidden_dim * num_heads, hidden_dim)), \n",
        "            # and also the first nn.Linear(hidden_dim * num_heads, hidden_dim) in post-message-passing.\n",
        "\n",
        "            hidden_dim = args.heads\n",
        "\n",
        "\n",
        "            \n",
        "            return GAT\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "          \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout,training=self.training)\n",
        "\n",
        "        x = self.post_mp(x)\n",
        "\n",
        "        if self.emb == True:\n",
        "            return x\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        return F.nll_loss(pred, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nW_XpEwASNZ"
      },
      "source": [
        "## Creating Our Own Message Passing Layer\n",
        "\n",
        "Now let's start implementing our own message passing layers! Working through this part will help us become acutely familiar with the behind the scenes work of implementing Pytorch Message Passing Layers, allowing us to build our own GNN models. To do so, we will work with and implement 3 critcal functions needed to define a PyG Message Passing Layer: `forward`, `message`, and `aggregate`.\n",
        "\n",
        "Before diving head first into the coding details, let us quickly review the key components of the message passing process. To do so, we will focus on a single round of messsage passing with respect to a single central node $x$. Before message passing, $x$ is associated with a feature vector $x^{l-1}$, and the goal of message passing is to update this feature vector as $x^l$. To do so, we implement the following steps: 1) each neighboring node $v$ passes its current message $v^{l-1}$ across the edge $(x, v)$ - 2) for the node $x$, we aggregate all of the messages of the neighboring nodes (for example through a sum or mean) - and 3) we transform the aggregated information by for example applying linear and non-linear transformations. Altogether, the message passing process is applied such that every node $u$ in our graph updates its embedding by acting as the central node $x$ in step 1-3 described above. \n",
        "\n",
        "Now, we extending this process to that of a single message passing layer, the job of a message passing layer is to update the current feature representation or embedding of each node in a graph by propagating and transforming information within the graph. Overall, the general paradigm of a message passing layers is: 1) pre-processing -> 2) **message passing** / propagation -> 3) post-processing. \n",
        "\n",
        "The `forward` fuction that we will implement for our message passing layer captures this execution logic. Namely, the `forward` function handles the pre and post-processing of node features / embeddings, as well as initiates message passing by calling the `propagate` function. \n",
        "\n",
        "\n",
        "The `propagate` function encapsulates the message passing process! It does so by calling three important functions: 1) `message`, 2) `aggregate`, and 3) `update`. Our implementation will vary slightly from this, as we will not explicitly implement `update`, but instead place the logic for updating node embeddings after message passing and within the `forward` function. To be more specific, after information is propagated (message passing), we can further transform the node embeddings outputed by `propagate`. Therefore, the output of `forward` is exactly the node embeddings after one GNN layer.\n",
        "\n",
        "Lastly, before starting to implement our own layer, let us dig a bit deeper into each of the functions described above:\n",
        "\n",
        "1. \n",
        "\n",
        "```\n",
        "def propagate(edge_index, x=(x_i, x_j), extra=(extra_i, extra_j), size=size):\n",
        "```\n",
        "Calling `propagate` initiates the message passing process. Looking at the function parameters, we highlight a couple of key parameters. \n",
        "\n",
        "  - `edge_index` is passed to the forward function and captures the edge structure of the graph.\n",
        "  - `x=(x_i, x_j)` represents the node features that will be used in message passing. In order to explain why we pass the tuple `(x_i, x_j)`, we first look at how our edges are represented. For every edge $(i, j) \\in \\mathcal{E}$, we can differentiate $i$ as the source or central node ($x_{central}$) and j as the neighboring node ($x_{neighbor}$). \n",
        "  \n",
        "    Taking the example of message passing above, for a central node $u$ we will aggregate and transform all of the messages associated with the nodes $v$ s.t. $(u, v) \\in \\mathcal{E}$ (i.e. $v \\in \\mathcal{N}_{u}$). Thus we see, the subscripts `_i` and `_j` allow us to specifcally differenciate features associated with central nodes (i.e. nodes  recieving message information) and neighboring nodes (i.e. nodes passing messages). \n",
        "\n",
        "    This is definitely a somewhat confusing concept; however, one key thing to remember / wrap your head around is that depending on the perspective, a node $x$ acts as a central node or a neighboring node. In fact, in undirected graphs we store both edge directions (i.e. $(i, j)$ and $(j, i)$). From the central node perspective, `x_i`, x is collecting neighboring information to update its embedding. From a neighboring node perspective, `x_j`, x is passing its message information along the edge connecting it to a different central node.\n",
        "\n",
        "  - `extra=(extra_i, extra_j)` represents additional information that we can associate with each node beyond its current feature embedding. In fact, we can include as many additional parameters of the form `param=(param_i, param_j)` as we would like. Again, we highlight that indexing with `_i` and `_j` allows us to differentiate central and neighboring nodes. \n",
        "\n",
        "  The output of the `propagate` function is a matrix of node embeddings after the message passing process and has shape $[N, d]$.\n",
        "\n",
        "2. \n",
        "```\n",
        "def message(x_j, ...):\n",
        "```\n",
        "The `message` function is called by propagate and constructs the messages from\n",
        "neighboring nodes $j$ to central nodes $i$ for each edge $(i, j)$ in *edge_index*. This function can take any argument that was initially passed to `propagate`. Furthermore, we can again differentiate central nodes and neighboring nodes by appending `_i` or `_j` to the variable name, .e.g. `x_i` and `x_j`. Looking more specifically at the variables, we have:\n",
        "\n",
        "  - `x_j` represents a matrix of feature embeddings for all neighboring nodes passing their messages along their respective edge (i.e. all nodes $j$ for edges $(i, j) \\in \\mathcal{E}$). Thus, its shape is $[|\\mathcal{E}|, d]$!\n",
        "  - In implementing GAT we will see how to access additional variables passed to propagate\n",
        "\n",
        "  Critically, we see that the output of the `message` function is a matrix of neighboring node embeddings ready to be aggregated, having shape $[|\\mathcal{E}|, d]$.\n",
        "\n",
        "3. \n",
        "```\n",
        "def aggregate(self, inputs, index, dim_size = None):\n",
        "```\n",
        "Lastly, the `aggregate` function is used to aggregate the messages from neighboring nodes. Looking at the parameters we highlight:\n",
        "\n",
        "  - `inputs` represents a matrix of the messages passed from neighboring nodes (i.e. the output of the `message` function).\n",
        "  - `index` has the same shape as `inputs` and tells us the central node that corresponding to each of the rows / messages $j$ in the `inputs` matrix. Thus, `index` tells us which rows / messages to aggregate for each central node.\n",
        "\n",
        "  The output of `aggregate` is of shape $[N, d]$.\n",
        "\n",
        "\n",
        "For additional resources refer to the PyG documentation for implementing custom message passing layers: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syDtxjxoCZgq"
      },
      "source": [
        "## GraphSage Implementation\n",
        "\n",
        "For our first GNN layer, we will implement the well known GraphSage ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)) layer! \n",
        "\n",
        "For a given *central* node $v$ with current embedding $h_v^{l-1}$, the message passing update rule to tranform $h_v^{l-1} \\rightarrow h_v^l$ is as follows: \n",
        "\n",
        "\\begin{equation}\n",
        "h_v^{(l)} = W_l\\cdot h_v^{(l-1)} + W_r \\cdot AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\})\n",
        "\\end{equation}\n",
        "\n",
        "where $W_1$ and $W_2$ are learanble weight matrices and the nodes $u$ are *neighboring* nodes. Additionally, we use mean aggregation for simplicity:\n",
        "\n",
        "\\begin{equation}\n",
        "AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\}) = \\frac{1}{|N(v)|} \\sum_{u\\in N(v)} h_u^{(l-1)}\n",
        "\\end{equation}\n",
        "\n",
        "One thing to note is that we're adding a **skip connection** to our GraphSage implementation through the term $W_l\\cdot h_v^{(l-1)}$. \n",
        "\n",
        "Before implementing this update rule, we encourage you to think about how different parts of the formulas above correspond with the functions outlined earlier: 1) `forward`, 2) `message`, and 3) `aggregate`. As a hint, we are given what the aggregation function is (i.e. mean aggregation)! Now the question remains, what are the messages passed by each neighbor nodes and when do we call the `propagate` function? \n",
        "\n",
        "Note: in this case the message function or messages are actually quite simple. Additionally, remember that the `propagate` function encapsulates the operations of / the outputs of the combined `message` and `aggregate` functions.\n",
        "\n",
        "\n",
        "Lastly, $\\ell$-2 normalization of the node embeddings is applied after each iteration.\n",
        "\n",
        "\n",
        "<font color='red'>For the following questions, please DON'T refer to any existing implementations online.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RwG4HqCFCaOD"
      },
      "outputs": [],
      "source": [
        "class GraphSage(MessagePassing):\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, normalize = True,\n",
        "                 bias = False, **kwargs):  \n",
        "        super(GraphSage, self).__init__(**kwargs)\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Define the layers needed for the message and update functions below.\n",
        "        ############################################################################\n",
        "\n",
        "      \n",
        "\n",
        "        #initiate in/out channels\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        #initiate linear layers (lin_l and lin_r)\n",
        "        self.lin_l = nn.Linear(in_channels, out_channels, bias)\n",
        "        self.lin_r = nn.Linear(in_channels, out_channels, bias)\n",
        "\n",
        "\n",
        "    \n",
        "        self.reset_parameters()\n",
        "\n",
        "\n",
        "\n",
        "       \n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin_l.reset_parameters()\n",
        "        self.lin_r.reset_parameters()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement message passing, as well as any post-processing (our update rule).\n",
        "        # 1. Call the propagate function to conduct the message passing.\n",
        "        #    1.1 See the description of propagate above or the following link for more information: \n",
        "        #        https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        #    1.2 We will only use the representation for neighbor nodes (x_j), so by default\n",
        "        #        we pass the same representation for central and neighbor nodes as x=(x, x). \n",
        "        # 2. Update our node embedding with skip connection from the previous layer.\n",
        "        # 3. If normalize is set, do L-2 normalization (defined in \n",
        "        #    torch.nn.functional)\n",
        "        #\n",
        "        ############################################################################\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        #Do message passing\n",
        "       \n",
        "        #add self loops\n",
        "        #edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "        #linearly transform the node feature matrix with lin_r\n",
        "      \n",
        "        x_r = torch.empty((Tensor.size(edge_index)[1], self.in_channels)).to(device)\n",
        "\n",
        "        # get neighbors and put it into x_r (neighbor vector)\n",
        "        for neighb in range(Tensor.size(edge_index)[1]):\n",
        "          x_r[neighb] = x[edge_index[1][neighb].item()][:]\n",
        "        \n",
        "        #propagate the message with mean aggregation\n",
        "        prop_out_before = self.message(x_r) #using MessagePassing.propagate \n",
        "        prop_out = self.aggregate(prop_out_before, edge_index[0])\n",
        "\n",
        "\n",
        "        \n",
        "        #update node mebedding with skip connection from previous layer (W_r * h)\n",
        "        #linearly transform node featuer with lin_l\n",
        "        x_l = self.lin_l(x)\n",
        "        #x_l = x_l.view(32, 2708)\n",
        "\n",
        "        #add the skip connection\n",
        "        #prop_out = prop_out.view(2708, 32)\n",
        "        skip_out = x_l + prop_out\n",
        "\n",
        "        #normalization by L-2 with F (torch.nn.functional)\n",
        "        #final_out = F.normalize(skip_out, p = 2, dim = -1)\n",
        "        final_out = F.normalize(skip_out)\n",
        "        \n",
        "\n",
        "\n",
        "        return final_out\n",
        "\n",
        "\n",
        "    def message(self, x_j):\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement your message function here.\n",
        "        # Hint: Look at the formulation of the mean aggregation function, focusing on \n",
        "        # what message each neighboring node passes.\n",
        "        ############################################################################\n",
        "        \n",
        "        return self.lin_r(x_j) # simple way to just return the message\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement your aggregate function here.\n",
        "        # See here as how to use torch_scatter.scatter: \n",
        "        # https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter\n",
        "        ############################################################################\n",
        "  \n",
        "        \n",
        "\n",
        "        return torch_scatter.scatter(inputs, index, dim = 0, reduce = \"mean\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjcfF3RACdLD"
      },
      "source": [
        "## GAT Implementation\n",
        "\n",
        "Attention mechanisms have become the state-of-the-art in many sequence-based tasks such as machine translation and learning sentence representations. One of the major benefits of attention-based mechanisms is their ability to focus on the most relevant parts of the input to make decisions. In this problem, we will see how attention mechanisms can be used to perform node classification over graph-structured data through the usage of Graph Attention Networks (GATs) ([Veličković et al. (2018)](https://arxiv.org/abs/1710.10903)).\n",
        "\n",
        "The building block of the Graph Attention Network is the graph attention layer, which is a variant of the aggregation function. Let $N$ be the number of nodes and $F$ be the dimension of the feature vector for each node. The input to each graph attentional layer is a set of node features: $\\mathbf{h} = \\{\\overrightarrow{h_1}, \\overrightarrow{h_2}, \\dots, \\overrightarrow{h_N}$\\}, $\\overrightarrow{h_i} \\in R^F$. The output of each graph attentional layer is a new set of node features, which may have a new dimension $F'$: $\\mathbf{h'} = \\{\\overrightarrow{h_1'}, \\overrightarrow{h_2'}, \\dots, \\overrightarrow{h_N'}\\}$, with $\\overrightarrow{h_i'} \\in \\mathbb{R}^{F'}$.\n",
        "\n",
        "We will now describe how this transformation is performed for each graph attention layer. First, a shared linear transformation parametrized by the weight matrix $\\mathbf{W} \\in \\mathbb{R}^{F' \\times F}$ is applied to every node. \n",
        "\n",
        "Next, we perform self-attention on the nodes. We use a shared attention function $a$:\n",
        "\\begin{equation} \n",
        "a : \\mathbb{R}^{F'} \\times \\mathbb{R}^{F'} \\rightarrow \\mathbb{R}.\n",
        "\\end{equation}\n",
        "\n",
        "that computes the attention coefficients capturing the importance of node $j$'s features to node $i$:\n",
        "\\begin{equation}\n",
        "e_{ij} = a(\\mathbf{W_l}\\overrightarrow{h_i}, \\mathbf{W_r} \\overrightarrow{h_j})\n",
        "\\end{equation}\n",
        "\n",
        "The most general formulation of self-attention allows every node to attend to all other nodes which drops all structural information. However, to utilize graph structure in the attention mechanisms, we use **masked attention**. In masked attention, we only compute attention coefficients $e_{ij}$ for nodes $j \\in \\mathcal{N}_i$ where $\\mathcal{N}_i$ is some neighborhood of node $i$ in the graph.\n",
        "\n",
        "To easily compare coefficients across different nodes, we normalize the coefficients across $j$ using a softmax function:\n",
        "\\begin{equation}\n",
        "\\alpha_{ij} = \\text{softmax}_j(e_{ij}) = \\frac{\\exp(e_{ij})}{\\sum_{k \\in \\mathcal{N}_i} \\exp(e_{ik})}\n",
        "\\end{equation}\n",
        "\n",
        "For this problem, our attention mechanism $a$ will be a single-layer feedforward neural network parametrized by a weight vectors $\\overrightarrow{a_l} \\in \\mathbb{R}^{F'}$ and $\\overrightarrow{a_r} \\in \\mathbb{R}^{F'}$, followed by a LeakyReLU nonlinearity (with negative input slope 0.2). Let $\\cdot^T$ represent transposition and $||$ represent concatenation. The coefficients computed by our attention mechanism may be expressed as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\alpha_{ij} = \\frac{\\exp\\Big(\\text{LeakyReLU}\\Big(\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i} + \\overrightarrow{a_r}^T\\mathbf{W_r}\\overrightarrow{h_j}\\Big)\\Big)}{\\sum_{k\\in \\mathcal{N}_i} \\exp\\Big(\\text{LeakyReLU}\\Big(\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i} + \\overrightarrow{a_r}^T\\mathbf{W_r}\\overrightarrow{h_k}\\Big)\\Big)}\n",
        "\\end{equation}\n",
        "\n",
        "For the following questions, we denote `alpha_l` = $\\alpha_l = [...,\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i},...] \\in \\mathcal{R}^n$ and `alpha_r` = $\\alpha_r = [..., \\overrightarrow{a_r}^T \\mathbf{W_r} \\overrightarrow{h_j}, ...] \\in \\mathcal{R}^n$.\n",
        "\n",
        "\n",
        "At every layer of GAT, after the attention coefficients are computed for that layer, the aggregation function can be computed by a weighted sum of neighborhood messages, where weights are specified by $\\alpha_{ij}$.\n",
        "\n",
        "Now, we use the normalized attention coefficients to compute a linear combination of the features corresponding to them. These aggregated features will serve as the final output features for every node.\n",
        "\n",
        "\\begin{equation}\n",
        "h_i' = \\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij} \\mathbf{W_r} \\overrightarrow{h_j}.\n",
        "\\end{equation}\n",
        "\n",
        "At this point, we have covered a lot of information! Before reading further about multi-head attention, we encourage you to go again through the excersize of thinking about what components of the attention mechanism correspond with the different functions: 1) `forward`, 2) `message`, and 3 `aggregate`. \n",
        "\n",
        "- Hint 1: Our aggregation is very similar to that of GraphSage except now we are using sum aggregation.\n",
        "- Hint 2: The terms we aggregate over again represent the individual message that each neighbor node j sends. Thus, we see that $\\alpha_{ij}$ is part of the message each node sends and is thus computed during the message step. This makes sense since an attention weight is associated with each edge in the graph.\n",
        "- Hint 3: Look at the terms in the definition of $\\alpha_{ij}$. What values do we want to pre-process and pass as parameters to the `propagate` function. The parameters of `message(..., x_j, alpha_j, alpha_i, ...)` should give a good hint.  \n",
        "\n",
        "### Multi-Head Attention\n",
        "To stabilize the learning process of self-attention, we use multi-head attention. To do this we use $K$ independent attention mechanisms, or ``heads'' compute output features as in the above equations. Then, we concatenate these output feature representations:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\overrightarrow{h_i}' = ||_{k=1}^K \\Big(\\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij}^{(k)} \\mathbf{W_r}^{(k)} \\overrightarrow{h_j}\\Big)\n",
        "\\end{equation}\n",
        "\n",
        "where $||$ is concentation, $\\alpha_{ij}^{(k)}$ are the normalized attention coefficients computed by the $k$-th attention mechanism $(a^k)$, and $\\mathbf{W}^{(k)}$ is the corresponding input linear transformation's weight matrix. Note that for this setting, $\\mathbf{h'} \\in \\mathbb{R}^{KF'}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w4j45gTpCeXO"
      },
      "outputs": [],
      "source": [
        "class GAT(MessagePassing):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, heads = 2,\n",
        "                 negative_slope = 0.2, dropout = 0., **kwargs):\n",
        "        super(GAT, self).__init__(node_dim=0, **kwargs)\n",
        "\n",
        "  \n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Define the layers needed for the message functions below.\n",
        "        # \n",
        "        # Pay attention to dimensions of the linear layers, since we're using \n",
        "        # multi-head attention.\n",
        "        ############################################################################\n",
        "\n",
        "        #initiate in/out channels\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #initiate linear layers (lin_l and lin_r) while splitting into different heads\n",
        "        self.lin_l = nn.Linear(in_channels, out_channels * args.heads, bias = False)\n",
        "        nn.init.xavier_uniform_(self.lin_l.weight)\n",
        "        self.lin_r = nn.Linear(in_channels, out_channels * args.heads, bias = False)\n",
        "        nn.init.xavier_uniform_(self.lin_r.weight)\n",
        "\n",
        "\n",
        "        #initialize attention layers\n",
        "        self.att_l = nn.Parameter(torch.Tensor(1, args.heads, out_channels))\n",
        "        nn.init.xavier_uniform_(self.att_l)\n",
        "\n",
        "        self.att_r = nn.Parameter(torch.Tensor(1, args.heads, out_channels))\n",
        "        nn.init.xavier_uniform_(self.att_r)\n",
        "\n",
        "        #initialize leakryRelu\n",
        "        self.leakyReLU = nn.LeakyReLU(negative_slope)\n",
        "\n",
        "        #heads\n",
        "        self.heads = args.heads\n",
        "\n",
        "        #dropout\n",
        "        self.perform_dropout = nn.Dropout(p = args.dropout)\n",
        "\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "\n",
        "        \n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.lin_l.weight)\n",
        "        nn.init.xavier_uniform_(self.lin_r.weight)\n",
        "        nn.init.xavier_uniform_(self.att_l)\n",
        "        nn.init.xavier_uniform_(self.att_r)\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "        \n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement message passing, as well as any pre- and post-processing (our update rule).\n",
        "        # 1. First apply linear transformation to node embeddings, and split that \n",
        "        #    into multiple heads. We use the same representations for source and\n",
        "        #    target nodes, but apply different linear weights (W_l and W_r)\n",
        "        # 2. Calculate alpha vectors for central nodes (alpha_l) and neighbor nodes (alpha_r).\n",
        "        # 3. Call propagate function to conduct the message passing. \n",
        "        #    3.1 Remember to pass alpha = (alpha_l, alpha_r) as a parameter.\n",
        "        #    3.2 See there for more information: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        # 4. Transform the output back to the shape of [N, H * C].\n",
        "        ############################################################################\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "        x_r = torch.empty((Tensor.size(edge_index)[1], self.in_channels)).to(device)\n",
        "\n",
        "        # get neighbors and put it into x_r (neighbor vector)\n",
        "        for neighb in range(Tensor.size(edge_index)[1]):\n",
        "          x_r[neighb] = x[edge_index[1][neighb].item()][:] \n",
        "\n",
        "        # Perform linear transformations with different linear weights\n",
        "        h_l = self.lin_l(x)\n",
        "        h_r = self.lin_r(x_r)\n",
        "        # split for each head\n",
        "        h_l = h_l.view(-1, self.heads, self.out_channels)\n",
        "        h_r = h_r.view(-1, self.heads, self.out_channels)\n",
        "\n",
        "        # Calculate alpha vectors with attention layers (heads)\n",
        "        alpha_l = (h_l * self.att_l).sum(dim = -1)\n",
        "        alpha_r = (h_r * self.att_r).sum(dim = -1)\n",
        "\n",
        "        x_j = h_r.index_select(0, edge_index[0]) #lifted tensor\n",
        "\n",
        "        # index select i and j-th elements in vector alpha l and alpha j \n",
        "        alpha_i = alpha_l.index_select(0, edge_index[0])\n",
        "        alpha_j = alpha_r.index_select(0, edge_index[1])\n",
        "        \n",
        "\n",
        "        num_nodes = x.shape[0]\n",
        "        num_nodes_r = x_r.shape[0]\n",
        "\n",
        "\n",
        "        prop_before = self.message(x_j, alpha_i, alpha_j, edge_index, ptr = None, size_i = num_nodes)\n",
        "\n",
        "        \n",
        "        #aggregate\n",
        "        prop_out = self.aggregate(prop_before, edge_index, size = num_nodes_r)\n",
        "\n",
        "      \n",
        "        #transform output back to shape of [N, H * C]\n",
        "        prop_out = prop_out.view(num_nodes, self.heads * self.out_channels)\n",
        "\n",
        "\n",
        "\n",
        "        return prop_out\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement your message function. Putting the attention in message \n",
        "        # instead of in update is a little tricky.\n",
        "        # 1. Calculate the final attention weights using alpha_i and alpha_j,\n",
        "        #    and apply leaky Relu.\n",
        "        # 2. Calculate softmax over the neighbor nodes for all the nodes. Use \n",
        "        #    torch_geometric.utils.softmax instead of the one in Pytorch.\n",
        "        # 3. Apply dropout to attention weights (alpha).\n",
        "        # 4. Multiply embeddings and attention weights. As a sanity check, the output\n",
        "        #    should be of shape [E, H, C].\n",
        "        # 5. ptr (LongTensor, optional): If given, computes the softmax based on\n",
        "        #    sorted inputs in CSR representation. You can simply pass it to softmax.\n",
        "        ############################################################################\n",
        "\n",
        "        # Calculate final attention weights\n",
        "        # select the indecies to get list of values for alpha_l and alpha_r\n",
        "      \n",
        "        # apply leaky RELU\n",
        "        leaky = self.leakyReLU(alpha_i + alpha_j)\n",
        "\n",
        "        #calculate softmax where will use ptr if it is given\n",
        "        if ptr != None:\n",
        "          sttention = softmax(leaky, ptr, num_nodes = size_i)\n",
        "        else:\n",
        "          attention = softmax(leaky, index[1], num_nodes = size_i)\n",
        "\n",
        "        attention = attention.unsqueeze(-1)\n",
        "\n",
        "        #apply dropout\n",
        "        attention = self.perform_dropout(attention)\n",
        "\n",
        "        # multiply embeddings and attnetion weights (shape is correct at torch.Size([10556, 2, 1]))\n",
        "        out = attention * x_j\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "    def aggregate(self, inputs, index, size, dim_size = None):\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement your aggregate function here.\n",
        "        # See here as how to use torch_scatter.scatter: https://pytorch-scatter.readthedocs.io/en/latest/_modules/torch_scatter/scatter.html\n",
        "        # Pay attention to \"reduce\" parameter is different from that in GraphSage.\n",
        "        ############################################################################\n",
        "    \n",
        "        #similar to GraphSage except using sum as aggregation method\n",
        "\n",
        "        index = index.view(size, args.heads)\n",
        "      \n",
        "        return torch_scatter.scatter(inputs, index, dim = self.node_dim, reduce = \"sum\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhwCIshroQ_L"
      },
      "source": [
        "## Building Optimizers\n",
        "\n",
        "Please build an Adam optimizer and return it in this function. But feel free to try some other types of optimizers on your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "X0JPEV2poQ_M"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def build_optimizer(params, args):\n",
        "    optimizer = optim.Adam(params, lr = args.lr, weight_decay = args.weight_decay)\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBYdWFwYCkwY"
      },
      "source": [
        "## Training and Testing\n",
        "\n",
        "Test your model every 10 epochs and save the accuracy to the file *CORA-GAT.txt* or *CORA-GraphSage.txt* recordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_tZMWRc8CmGg"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from tqdm import trange\n",
        "import pandas as pd\n",
        "import copy\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def train(dataset, args, enable):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    print(\"Node task. test set size:\", np.sum(dataset[0]['test_mask'].numpy()))\n",
        "    print()\n",
        "    test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "    # build model\n",
        "    model = GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, args).to(device)\n",
        "    opt = build_optimizer(model.parameters(), args)\n",
        "\n",
        "    model.train() #training starts here\n",
        "\n",
        "    # get data of graph through iterating through the loader\n",
        "\n",
        "    # data saved\n",
        "    loader_data = next(iter(loader)).to(device) #save it to device\n",
        "\n",
        "    # store results of loss and accuracy\n",
        "\n",
        "    epoch_acc = []\n",
        "    epoch_loss = []\n",
        "\n",
        "\n",
        "    # iterate through epochs to perform predictions\n",
        "    for curr_iter in range(args.num_iter):\n",
        "      print(\"Iteration {} of {} Model\".format(curr_iter + 1, args.model_type))\n",
        "      for epoch in range(args.epochs):\n",
        "\n",
        "        # get training loader nodes\n",
        "        train_loader = DataLoader(dataset[0]['train_mask'], batch_size=args.batch_size, shuffle=False)\n",
        "        batch_loss = []\n",
        "\n",
        "        #label current epoch\n",
        "        print('Current epoch at {}/{}'.format(epoch+1, args.epochs))\n",
        "\n",
        "        itr_count = 0\n",
        "        for curr_step, data in enumerate(iter(train_loader)):\n",
        "\n",
        "          # message pass\n",
        "          out = model(loader_data)\n",
        "\n",
        "          #open predictions of node levels\n",
        "          node_out = out[itr_count:itr_count+len(data)][:]\n",
        "\n",
        "          # get labels (y) to start calculating\n",
        "          labels = loader_data.y[itr_count:itr_count+len(data)]\n",
        "\n",
        "\n",
        "          final_node_out = node_out[data]\n",
        "          final_labels = labels[data]\n",
        "\n",
        "          # in the case that there are no labels\n",
        "          if len(final_labels)==0:\n",
        "            break\n",
        "          else:\n",
        "            # get the loss and append the loss into a array with batch:loss\n",
        "            loss = model.loss(final_node_out, final_labels)\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "            # optimize time by going backwards\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            itr_count += len(data)\n",
        "\n",
        "        epoch_loss.append(sum(batch_loss)/len(batch_loss)) # getting avery loss \n",
        "\n",
        "\n",
        "        # once the epochs are done\n",
        "        if epoch + 1 == args.epochs:\n",
        "\n",
        "          # batch testing \n",
        "          test_loader = DataLoader(dataset[0]['test_mask'], batch_size=args.batch_size, shuffle=False)\n",
        "          iteration_test = iter(test_loader)\n",
        "\n",
        "          #AFTER IMPLEMENTING GAT, WRITE A FOR LOOP TO RUN THIS OVER HOWEVER MANY TIMES FOR EACH 10 EPPOCHS\n",
        "          #WRITE TO epoch_acc array\n",
        "          test_acc = test(dataset, iteration_test, model)\n",
        "\n",
        "\n",
        "          epoch_acc.append(test_acc)\n",
        "        \n",
        "\n",
        "    #HAVE TO DO THIS AFTER GAT WORKS TO WRITE INTO TEXT FILES... (Only doing this for first 2 questions)\n",
        "    #write into text files\n",
        "    if enable == True:\n",
        "      if args.model_type == \"GraphSage\":\n",
        "        GS_file = open(\"/content/CORA_GraphSage.txt\", \"w+\")\n",
        "\n",
        "        #save into own array\n",
        "        #convert to string\n",
        "        conver_epoch_acc = str(epoch_acc)\n",
        "        conver_loss = str(epoch_loss)\n",
        "        \n",
        "\n",
        "        GS_file.write(\"Accuracy Per {} Epoch \\n\".format(args.epochs))\n",
        "        GS_file.write(conver_epoch_acc + \"\\n\")\n",
        "        GS_file.write(\"Loss Per Epoch \\n\")\n",
        "        GS_file.write(conver_loss + \"\\n\")\n",
        "        \n",
        "        GS_file.close()\n",
        "        \n",
        "\n",
        "\n",
        "      elif args.model_type == \"GAT\":\n",
        "        GAT_file = open(\"/content/CORA_GAT.txt\", \"w+\")\n",
        "        conver_epoch_acc = str(epoch_acc)\n",
        "        conver_loss = str(epoch_loss)\n",
        "    \n",
        "\n",
        "        GAT_file.write(\"Accuracy Per {} Epoch \\n\".format(args.epochs))\n",
        "        GAT_file.write(conver_epoch_acc + \"\\n\")\n",
        "        GAT_file.write(\"Loss Per Epoch \\n\")\n",
        "        GAT_file.write(conver_loss + \"\\n\")\n",
        "      \n",
        "        GAT_file.close()\n",
        "\n",
        "\n",
        "    #for plotting purposes\n",
        "    print(\"Finished Running {}\".format(args.model_type))\n",
        "    return epoch_acc, epoch_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "def test(dataset, loader, test_model, is_validation=False, save_model_preds=False, model_type=None):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    test_model.eval()\n",
        "\n",
        "    # get graph (similar to train method)\n",
        "    test_loader = DataLoader(dataset, batch_size = args.batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "    # data saved\n",
        "    loader_data = next(iter(test_loader)).to(device) #save it to device\n",
        "\n",
        "    #message pass\n",
        "    out = test_model(loader_data)\n",
        "\n",
        "\n",
        "    # attributes to calculate accuracy\n",
        "    corr = 0\n",
        "    tot = 0\n",
        "\n",
        "    # Note that Cora is only one graph!\n",
        "    #enumerate similar to train\n",
        "    itr_count = 0\n",
        "    for curr_step, data in enumerate(iter(loader)):\n",
        "\n",
        "      #open predictions of node levels\n",
        "      node_out = out[itr_count:itr_count+len(data)][:]\n",
        "\n",
        "      # get labels (y) to start calculating\n",
        "      labels = loader_data.y[itr_count:itr_count+len(data)]\n",
        "      final_node_out = node_out[data]\n",
        "      final_labels = labels[data]\n",
        "\n",
        "      if len(final_labels)==0:\n",
        "        continue\n",
        "        \n",
        "      for label in range(len(final_labels)):\n",
        "        tot += 1\n",
        "        #get prediction (max node)\n",
        "        pred = torch.argmax(final_node_out[label][:]).item()\n",
        "        #if it is equal to the label in testing, we can count it as correct\n",
        "        if pred == int(final_labels[label]):\n",
        "          corr += 1\n",
        "\n",
        "      #iterate\n",
        "      itr_count += len(data)\n",
        "\n",
        "    return corr/tot\n",
        "\n",
        "      \n",
        "  \n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qe9B45l9Cpz2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "7d2cfe1f-21d8-411a-e124-f655bc992939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n",
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1 and 2\n",
            "Node task. test set size: 1000\n",
            "\n",
            "Iteration 1 of GraphSage Model\n",
            "Current epoch at 1/10\n",
            "Current epoch at 2/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9a65a894ccd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m#Questions 1 and 2 -> Get Normal Run through with number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Question 1 and 2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mresults_Q1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0macc_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_Q1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mloss_y\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mresults_Q1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-a1ba164cb41b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, args, enable)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;31m# optimize time by going backwards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mitr_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def run_plot(dataset, args, y_acc_axis, y_loss_axis, x_acc_axis, x_loss_axis, x_acc_label, x_loss_label, x_acc_title, x_loss_title): # To run and Plot the results\n",
        "        \n",
        "  #PLOT \n",
        "  \n",
        "  #plot accuracy graph\n",
        "  plt.figure()\n",
        "  plt.scatter(x_acc_axis, y_acc_axis)\n",
        "  plt.title(x_acc_title)\n",
        "  plt.xlabel(x_acc_label)\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.savefig(x_acc_title)\n",
        "\n",
        "  #plot loss graph\n",
        "  plt.figure()\n",
        "  plt.scatter(x_loss_axis, y_loss_axis)\n",
        "  plt.title(x_loss_title)\n",
        "  plt.xlabel(x_loss_label)\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.savefig(x_loss_title)\n",
        "\n",
        "\n",
        "for args in [ #added a num_iteration for number of 10 epochs to go through\n",
        "    {'num_iter': 5, 'model_type': 'GraphSage', 'dataset': 'cora', 'num_layers': 2, 'heads':3, 'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 10, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.01},\n",
        "]:\n",
        "    args = objectview(args)\n",
        "    for model in ['GraphSage','GAT']: #this has to be modified if want to just test out one model\n",
        "        args.model_type = model\n",
        "\n",
        "        # Match the dimension.\n",
        "        if model == 'GAT':\n",
        "          args.heads = 2\n",
        "        else:\n",
        "          args.heads = 1\n",
        "\n",
        "        if args.dataset == 'cora':\n",
        "            dataset = Planetoid(root='/tmp/cora', name='Cora')\n",
        "        else:\n",
        "            raise NotImplementedError(\"Unknown dataset\") \n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Train the model and plot the training loss and test accuracy for both GAT and GraphSage\n",
        "        ############################################################################\n",
        "\n",
        "        #Run and get results\n",
        "\n",
        "        #Questions 1 and 2 -> Get Normal Run through with number of iterations\n",
        "        print(\"Question 1 and 2\")\n",
        "        results_Q1 = train(dataset, args, enable = True)\n",
        "        acc_y = results_Q1[0]\n",
        "        loss_y  = results_Q1[1]\n",
        "\n",
        "\n",
        "        # for plotting purposes\n",
        "        acc_x = []\n",
        "        for i in range(args.num_iter):\n",
        "          acc_x.append(i + 1)\n",
        "\n",
        "        loss_x = []\n",
        "        for i in range(args.epochs * args.num_iter):\n",
        "          loss_x.append(i + 1)\n",
        "\n",
        "        x_acc_title = \"{} Model Accuracy Graph Over {} Epochs\".format(args.model_type, args.epochs * args.num_iter)\n",
        "        x_acc_label = \"Per {} Epochs\".format(args.epochs)\n",
        "        \n",
        "        x_loss_title = \"{} Model Loss Graph Over {} Epochs\".format(args.model_type, args.epochs * args.num_iter)\n",
        "        x_loss_label = \"Number of {} Epochs\".format(args.epochs)\n",
        "\n",
        "                                                         \n",
        "        run_plot(dataset, args, acc_y, loss_y, acc_x, loss_x, x_acc_label, x_loss_label, x_acc_title, x_loss_title)\n",
        "\n",
        "        #Question 3 Change GNN Layers and Observe\n",
        "        print(\"Question 3\")\n",
        "\n",
        "        layers_acc = []\n",
        "        layers_loss_pre = []\n",
        "        layers_loss = []\n",
        "\n",
        "        max_layers = 5\n",
        "\n",
        "        for num_layers in range(2, max_layers + 1): #how many layers to test\n",
        "          print(\"Running with {} layers\".format(num_layers))\n",
        "          args.num_layers = num_layers\n",
        "          args.num_iter = 1 # for sake of run time\n",
        "          results_Q3 = train(dataset, args, enable = False) # do not make text files\n",
        "          layers_acc.append(results_Q3[0])\n",
        "          layers_loss_pre.append(results_Q3[1])\n",
        "          \n",
        "        layers_loss = [j for sub in layers_loss_pre for j in sub] #flatten \n",
        "\n",
        "        # for plotting purposes\n",
        "        layers_plot_acc = []\n",
        "        for i in range(2, max_layers + 1):\n",
        "          layers_plot_acc.append(i)\n",
        "\n",
        "        layers_plot_loss = []\n",
        "        for i in range(2, max_layers + 1):\n",
        "          for j in range(0, args.epochs):\n",
        "            layers_plot_loss.append(i)\n",
        "\n",
        "        x_layeracc_title = \"{} Model Accuracy Graph Over {} Layers\".format(args.model_type, max_layers)\n",
        "        x_layeracc_label = \"{} Layers\".format(max_layers)\n",
        "        \n",
        "        x_layerloss_title = \"{} Model Loss Graph Over {} Layers\".format(args.model_type, max_layers)\n",
        "        x_layerloss_label = \"{} Layers\".format(max_layers)\n",
        "\n",
        "                                                        \n",
        "        run_plot(dataset, args, layers_acc, layers_loss, layers_plot_acc, layers_plot_loss, x_layeracc_label, x_layerloss_label, x_layeracc_title, x_layerloss_title)\n",
        "\n",
        "\n",
        "        #Question 4 -> For GAT only, change number of heads\n",
        "        \n",
        "\n",
        "        if (args.model_type == 'GAT'):\n",
        "          print(\"Question 4 -> Only for GAT (manipulating heads)\")\n",
        "          head_acc = []\n",
        "          head_loss = []\n",
        "\n",
        "          max_heads = 5\n",
        "\n",
        "          head_loss_pre = []\n",
        "          for num_heads in range(2, max_heads + 1): #how many layers to test\n",
        "            print(\"Running with {} heads\".format(num_heads))\n",
        "            args.heads = 2\n",
        "            args.num_iter = 1 # for sake of run time\n",
        "            results_Q4 = train(dataset, args, enable = False)\n",
        "            head_acc.append(results_Q4[0])\n",
        "            head_loss_pre.append(results_Q4[1])\n",
        "          \n",
        "          head_loss = [j for sub in head_loss_pre for j in sub] #flatten \n",
        "\n",
        "          heads_plot_acc = []\n",
        "          for i in range(2, max_heads + 1):\n",
        "            heads_plot_acc.append(i)\n",
        "\n",
        "          heads_plot_loss = []\n",
        "          for i in range(2, max_heads + 1):\n",
        "            for j in range(0, args.epochs):\n",
        "              heads_plot_loss.append(i)\n",
        "          \n",
        "          x_headacc_title = \"{} Model Accuracy Graph Over {} Heads\".format(args.model_type, max_heads)\n",
        "          x_headacc_label = \"{} Heads\".format(max_heads)\n",
        "          \n",
        "          x_headloss_title = \"{} Model Loss Graph Over {} Heads\".format(args.model_type, max_heads)\n",
        "          x_headloss_label = \"{} Heads\".format(max_heads)\n",
        "\n",
        "                                                          \n",
        "          run_plot(dataset, args, head_acc, head_loss, heads_plot_acc, heads_plot_loss, x_headacc_label, x_headloss_label, x_headacc_title, x_headloss_title)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlCtBEBLMBkR"
      },
      "source": [
        "## Question 1: What is the best accuracy obtained on test set for GAT? (10 points)\n",
        "\n",
        "\n",
        "Run the cells above and save your GAT model accuracy every ten epochs to the file *CORA-GAT.txt*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPymzwbM27Fv"
      },
      "source": [
        "## Question 2: What is the best accuracy obtained on test set for GraphSage? (10 points)\n",
        "\n",
        "\n",
        "Run the cells above and save your GraphSage model accuracy every ten epochs to the file *CORA-GraphSage.txt*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_Oenew23GXU"
      },
      "source": [
        "## Question 3: Increase the number of GNN layers and observe how the performance changes. Write down you observation and analysis. (10 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHeT5g7B6PWx"
      },
      "source": [
        "## Question 4: Change the number of attention heads and observe how the performance changes. Write down you observation and analysis. (10 points)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "cs570_hw2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}